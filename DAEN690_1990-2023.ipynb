{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e472d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "from functools import reduce\n",
    "\n",
    "# Column names for CSV files after downloading since it doesnt have any labels\n",
    "column_names = [\n",
    "    'cty', 'region', 'state', 'year', 'month', 'prcp',\n",
    "    '1', '2', '3', '4', '5', '6', '7', '8', '9', '10',\n",
    "    '11', '12', '13', '14', '15', '16', '17', '18', '19',\n",
    "    '20', '21', '22', '23', '24', '25', '26', '27', '28',\n",
    "    '29', '30', '31'\n",
    "]\n",
    "\n",
    "def download_and_process_data(year, month, data_type, scale, base_directory):\n",
    "    base_url = \"https://www.ncei.noaa.gov/pub/data/daily-grids/v1-0-0/averages/\"\n",
    "    target_file = f\"{data_type}-{year}{month:02d}-{scale}.csv\"\n",
    "    file_url = f\"{base_url}{year}/{target_file}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(file_url)\n",
    "        response.raise_for_status()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error downloading {file_url}: {e}\")\n",
    "        return None\n",
    "\n",
    "    temp_directory = os.path.join(base_directory, \"temp\")\n",
    "    if not os.path.exists(temp_directory):\n",
    "        os.makedirs(temp_directory)\n",
    "    temp_file_path = os.path.join(temp_directory, target_file)\n",
    "    with open(temp_file_path, 'w') as file:\n",
    "        file.write(response.text)\n",
    "    \n",
    "    return process_file(temp_file_path, data_type, year, month, scale, base_directory)\n",
    "\n",
    "def process_file(file_path, data_type, year, month, scale, base_directory):\n",
    "    df = pd.read_csv(file_path, names=column_names, header=None)\n",
    "\n",
    "    filtered_df = df[df['state'].str.startswith('VA:')]\n",
    "    new_data = []\n",
    "    for index, row in filtered_df.iterrows():\n",
    "        for day in range(1, 32):\n",
    "            day_str = str(day)\n",
    "            if day_str in filtered_df.columns:\n",
    "                value = row[day_str]\n",
    "                new_row = {\n",
    "                    'date': f\"{row['month']}/{day}/{row['year']}\",\n",
    "                    'year': row['year'],\n",
    "                    'month': row['month'],\n",
    "                    'day': day,\n",
    "                    'state': row['state'][:2],\n",
    "                    'county': row['state'][3:],\n",
    "                    'region': row['region'],\n",
    "                    'value': value,\n",
    "                    'data_type': data_type\n",
    "                }\n",
    "                new_data.append(new_row)\n",
    "\n",
    "    new_df = pd.DataFrame(new_data)\n",
    "    \n",
    "    transformed_directory = os.path.join(base_directory, f\"{year}\", f\"{scale}_transformed\")\n",
    "    if not os.path.exists(transformed_directory):\n",
    "        os.makedirs(transformed_directory)\n",
    "    transformed_file_name = f\"{year}{str(month).zfill(2)}_{data_type}_transformed.csv\"\n",
    "    transformed_file_path = os.path.join(transformed_directory, transformed_file_name)\n",
    "    new_df.to_csv(transformed_file_path, index=False)\n",
    "    \n",
    "    print(f\"Processed and saved transformed data: {transformed_file_path}\")\n",
    "    return transformed_file_path\n",
    "\n",
    "def merge_processed_files(processed_files, base_output_path, year, scale):\n",
    "    dfs = []\n",
    "    for file_path in processed_files:\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            dfs.append(df)\n",
    "    \n",
    "    if dfs:\n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "        pivoted_df = combined_df.pivot_table(index=['date', 'year', 'month', 'day', 'state', 'county', 'region'],\n",
    "                                             columns='data_type', values='value', aggfunc='first').reset_index()\n",
    "        \n",
    "        \n",
    "        pivoted_df.columns.name = None\n",
    "        pivoted_df = pivoted_df.rename(columns={col: f\"{col}\" for col in pivoted_df.columns})\n",
    "\n",
    "        final_csv_file_path = os.path.join(base_output_path, f\"{year}_{scale}_merged.csv\")\n",
    "        pivoted_df.to_csv(final_csv_file_path, index=False)\n",
    "        print(f\"All files for {year} and scale {scale} have been successfully merged into {final_csv_file_path}.\")\n",
    "\n",
    "def process_files_for_year_and_scale(year, data_types, scale, base_directory):\n",
    "    processed_files = []\n",
    "    for month in range(1, 13):\n",
    "        for data_type in data_types:\n",
    "            file_path = download_and_process_data(year, month, data_type, scale, base_directory)\n",
    "            if file_path:\n",
    "                processed_files.append(file_path)\n",
    "    return processed_files\n",
    "\n",
    "def process_range(start_date, end_date, data_types, scale, base_directory):\n",
    "    # Initialize an empty list outside the loop to collect processed file paths for each year\n",
    "    processed_files_for_year = []\n",
    "    current_year = start_date.year  # Track the current year being processed\n",
    "\n",
    "    for current_date in pd.date_range(start=start_date, end=end_date, freq='MS'):\n",
    "        year = current_date.year\n",
    "        month = current_date.month\n",
    "\n",
    "        \n",
    "        if year != current_year:\n",
    "            \n",
    "            if processed_files_for_year:\n",
    "                base_output_path = os.path.join(base_directory, f\"{current_year}\", f\"{scale}_merged\")\n",
    "                if not os.path.exists(base_output_path):\n",
    "                    os.makedirs(base_output_path)\n",
    "                merge_processed_files(processed_files_for_year, base_output_path, current_year, scale)\n",
    "                processed_files_for_year = []  \n",
    "            \n",
    "            current_year = year  \n",
    "\n",
    "        \n",
    "        for data_type in data_types:\n",
    "            file_path = download_and_process_data(year, month, data_type, scale, base_directory)\n",
    "            if file_path:\n",
    "                processed_files_for_year.append(file_path)\n",
    "    \n",
    "    \n",
    "    if processed_files_for_year:\n",
    "        base_output_path = os.path.join(base_directory, f\"{year}\", f\"{scale}_merged\")\n",
    "        if not os.path.exists(base_output_path):\n",
    "            os.makedirs(base_output_path)\n",
    "        merge_processed_files(processed_files_for_year, base_output_path, year, scale)\n",
    "\n",
    "\n",
    "\n",
    "# Give start date and end date\n",
    "#give your local path\n",
    "start_date = datetime(1990, 1, 1)\n",
    "end_date = datetime(2023, 12, 31)\n",
    "data_types = [\"prcp\", \"tavg\", \"tmin\", \"tmax\"]\n",
    "scale = 'cty-scaled'\n",
    "base_directory = \"/Users/vaidhikraj/Downloads/\"\n",
    "\n",
    "\n",
    "process_range(start_date, end_date, data_types, scale, base_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e2f9e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data saved to: /Users/vaidhikraj/Downloads/virginia_1990-2023/merged/virginia_1990-2023.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "directory = '/Users/vaidhikraj/Downloads/virginia_1990-2023/'  # Update with the directory containing your CSV files\n",
    "\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "\n",
    "\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "\n",
    "output_csv_file_path = '/Users/vaidhikraj/Downloads/virginia_1990-2023/merged/virginia_1990-2023.csv'\n",
    "\n",
    "\n",
    "merged_df.to_csv(output_csv_file_path, index=False)\n",
    "\n",
    "print(f\"Merged data saved to: {output_csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aebd459c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>state</th>\n",
       "      <th>county</th>\n",
       "      <th>region</th>\n",
       "      <th>prcp</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1129392</th>\n",
       "      <td>1/1/2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>VA</td>\n",
       "      <td>Accomack County</td>\n",
       "      <td>44001</td>\n",
       "      <td>17.98</td>\n",
       "      <td>12.77</td>\n",
       "      <td>16.28</td>\n",
       "      <td>9.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129393</th>\n",
       "      <td>1/1/2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>VA</td>\n",
       "      <td>Albemarle County</td>\n",
       "      <td>44003</td>\n",
       "      <td>7.88</td>\n",
       "      <td>10.27</td>\n",
       "      <td>14.42</td>\n",
       "      <td>6.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129394</th>\n",
       "      <td>1/1/2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>VA</td>\n",
       "      <td>Alexandria city</td>\n",
       "      <td>44510</td>\n",
       "      <td>6.10</td>\n",
       "      <td>10.31</td>\n",
       "      <td>14.08</td>\n",
       "      <td>6.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129395</th>\n",
       "      <td>1/1/2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>VA</td>\n",
       "      <td>Alleghany County</td>\n",
       "      <td>44005</td>\n",
       "      <td>6.61</td>\n",
       "      <td>7.61</td>\n",
       "      <td>10.98</td>\n",
       "      <td>4.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1129396</th>\n",
       "      <td>1/1/2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>VA</td>\n",
       "      <td>Amelia County</td>\n",
       "      <td>44007</td>\n",
       "      <td>14.86</td>\n",
       "      <td>10.72</td>\n",
       "      <td>15.89</td>\n",
       "      <td>5.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178491</th>\n",
       "      <td>9/9/2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>VA</td>\n",
       "      <td>Williamsburg city</td>\n",
       "      <td>44830</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.36</td>\n",
       "      <td>33.10</td>\n",
       "      <td>21.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178492</th>\n",
       "      <td>9/9/2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>VA</td>\n",
       "      <td>Winchester city</td>\n",
       "      <td>44840</td>\n",
       "      <td>12.62</td>\n",
       "      <td>23.66</td>\n",
       "      <td>29.83</td>\n",
       "      <td>17.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178493</th>\n",
       "      <td>9/9/2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>VA</td>\n",
       "      <td>Wise County</td>\n",
       "      <td>44195</td>\n",
       "      <td>2.41</td>\n",
       "      <td>21.47</td>\n",
       "      <td>25.79</td>\n",
       "      <td>17.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178494</th>\n",
       "      <td>9/9/2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>VA</td>\n",
       "      <td>Wythe County</td>\n",
       "      <td>44197</td>\n",
       "      <td>4.49</td>\n",
       "      <td>21.23</td>\n",
       "      <td>27.36</td>\n",
       "      <td>15.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178495</th>\n",
       "      <td>9/9/2023</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>VA</td>\n",
       "      <td>York County</td>\n",
       "      <td>44199</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.57</td>\n",
       "      <td>32.66</td>\n",
       "      <td>22.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49104 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             date  year  month  day state              county  region   prcp  \\\n",
       "1129392  1/1/2023  2023      1    1    VA     Accomack County   44001  17.98   \n",
       "1129393  1/1/2023  2023      1    1    VA    Albemarle County   44003   7.88   \n",
       "1129394  1/1/2023  2023      1    1    VA     Alexandria city   44510   6.10   \n",
       "1129395  1/1/2023  2023      1    1    VA    Alleghany County   44005   6.61   \n",
       "1129396  1/1/2023  2023      1    1    VA       Amelia County   44007  14.86   \n",
       "...           ...   ...    ...  ...   ...                 ...     ...    ...   \n",
       "1178491  9/9/2023  2023      9    9    VA   Williamsburg city   44830   0.00   \n",
       "1178492  9/9/2023  2023      9    9    VA     Winchester city   44840  12.62   \n",
       "1178493  9/9/2023  2023      9    9    VA         Wise County   44195   2.41   \n",
       "1178494  9/9/2023  2023      9    9    VA        Wythe County   44197   4.49   \n",
       "1178495  9/9/2023  2023      9    9    VA         York County   44199   0.00   \n",
       "\n",
       "          tavg   tmax   tmin  \n",
       "1129392  12.77  16.28   9.27  \n",
       "1129393  10.27  14.42   6.12  \n",
       "1129394  10.31  14.08   6.55  \n",
       "1129395   7.61  10.98   4.25  \n",
       "1129396  10.72  15.89   5.56  \n",
       "...        ...    ...    ...  \n",
       "1178491  27.36  33.10  21.62  \n",
       "1178492  23.66  29.83  17.49  \n",
       "1178493  21.47  25.79  17.16  \n",
       "1178494  21.23  27.36  15.10  \n",
       "1178495  27.57  32.66  22.49  \n",
       "\n",
       "[49104 rows x 11 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f4c10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/47/w_v05zrj7n1b0dm26jvljqyh0000gn/T/ipykernel_48397/698381393.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  weather_data_table['WeatherDataID'] = weather_data_table.index + 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables saved successfully.\n"
     ]
    }
   ],
   "source": [
    "#redudancy removal\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "file_path = \"/Users/vaidhikraj/Downloads/virginia_1990-2023/merged/virginia_1990-2023.csv\"\n",
    "\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "date_table = df[['year', 'month', 'day']].drop_duplicates().reset_index(drop=True)\n",
    "date_table['DateID'] = date_table.index + 1\n",
    "\n",
    "\n",
    "county_table = df[['state', 'county', 'region']].drop_duplicates().reset_index(drop=True)\n",
    "county_table['CountyID'] = county_table.index + 1\n",
    "\n",
    "\n",
    "weather_data = df.merge(date_table, on=['year', 'month', 'day'])\n",
    "weather_data = weather_data.merge(county_table, on=['state', 'county', 'region'])\n",
    "weather_data_table = weather_data[['DateID', 'CountyID', 'prcp', 'tavg', 'tmin', 'tmax']]\n",
    "weather_data_table['WeatherDataID'] = weather_data_table.index + 1\n",
    "\n",
    "\n",
    "date_table_file = os.path.join(os.path.dirname(file_path), 'date_table.csv')\n",
    "county_table_file = os.path.join(os.path.dirname(file_path), 'county_table.csv')\n",
    "weather_data_table_file = os.path.join(os.path.dirname(file_path), 'weather_data_table.csv')\n",
    "\n",
    "\n",
    "date_table.to_csv(date_table_file, index=False)\n",
    "county_table.to_csv(county_table_file, index=False)\n",
    "weather_data_table.to_csv(weather_data_table_file, index=False)\n",
    "\n",
    "print(\"Tables saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea0987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
